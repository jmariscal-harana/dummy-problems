{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "SBG_A2kwTaLh",
        "outputId": "e9b71d8a-84c6-4458-d2c8-70db15685b67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 0, Step: 0 | State: [ 0.04371392  0.21160294 -0.04302173 -0.2617506 ], Reward: 1.0, Done: False\n",
            "Episode: 0, Step: 1 | State: [ 0.04794598  0.40731177 -0.04825674 -0.5676867 ], Reward: 1.0, Done: False\n",
            "Episode: 0, Step: 2 | State: [ 0.05609221  0.21289875 -0.05961047 -0.29058862], Reward: 1.0, Done: False\n",
            "Episode: 0, Step: 3 | State: [ 0.06035019  0.4088178  -0.06542225 -0.6014603 ], Reward: 1.0, Done: False\n",
            "Episode: 0, Step: 4 | State: [ 0.06852654  0.604791   -0.07745145 -0.9140116 ], Reward: 1.0, Done: False\n",
            "Episode: 0, Step: 5 | State: [ 0.08062236  0.8008703  -0.09573168 -1.2299968 ], Reward: 1.0, Done: False\n",
            "Episode: 0, Step: 6 | State: [ 0.09663977  0.99708456 -0.12033162 -1.5510727 ], Reward: 1.0, Done: False\n",
            "Episode: 0, Step: 7 | State: [ 0.11658145  0.803594   -0.15135308 -1.2982278 ], Reward: 1.0, Done: False\n",
            "Episode: 0, Step: 8 | State: [ 0.13265334  0.6106826  -0.17731763 -1.056497  ], Reward: 1.0, Done: False\n",
            "Episode: 0, Step: 9 | State: [ 0.14486699  0.41829658 -0.19844757 -0.82430136], Reward: 1.0, Done: False\n",
            "Episode: 0, Step: 10 | State: [ 0.15323292  0.6154989  -0.2149336  -1.1722608 ], Reward: 1.0, Done: True\n",
            "Episode 0 finished after 10 steps.\n",
            "Episode: 1, Step: 0 | State: [-0.00803546  0.21441796 -0.03361958 -0.34460193], Reward: 1.0, Done: False\n",
            "Episode: 1, Step: 1 | State: [-0.0037471   0.01979    -0.04051162 -0.06270726], Reward: 1.0, Done: False\n",
            "Episode: 1, Step: 2 | State: [-0.0033513   0.21546866 -0.04176576 -0.3678916 ], Reward: 1.0, Done: False\n",
            "Episode: 1, Step: 3 | State: [ 0.00095807  0.41115844 -0.0491236  -0.6734458 ], Reward: 1.0, Done: False\n",
            "Episode: 1, Step: 4 | State: [ 0.00918124  0.60692745 -0.06259251 -0.9811817 ], Reward: 1.0, Done: False\n",
            "Episode: 1, Step: 5 | State: [ 0.02131979  0.8028299  -0.08221614 -1.2928501 ], Reward: 1.0, Done: False\n",
            "Episode: 1, Step: 6 | State: [ 0.03737639  0.60884356 -0.10807315 -1.0269978 ], Reward: 1.0, Done: False\n",
            "Episode: 1, Step: 7 | State: [ 0.04955326  0.80522525 -0.1286131  -1.3515633 ], Reward: 1.0, Done: False\n",
            "Episode: 1, Step: 8 | State: [ 0.06565776  1.0017064  -0.15564437 -1.681559  ], Reward: 1.0, Done: False\n",
            "Episode: 1, Step: 9 | State: [ 0.08569189  0.8086924  -0.18927555 -1.4411128 ], Reward: 1.0, Done: False\n",
            "Episode: 1, Step: 10 | State: [ 0.10186574  0.6163376  -0.2180978  -1.2130488 ], Reward: 1.0, Done: True\n",
            "Episode 1 finished after 10 steps.\n",
            "Episode: 2, Step: 0 | State: [ 0.044831    0.17728944  0.0402181  -0.2920165 ], Reward: 1.0, Done: False\n",
            "Episode: 2, Step: 1 | State: [ 0.04837679  0.37181556  0.03437777 -0.5717488 ], Reward: 1.0, Done: False\n",
            "Episode: 2, Step: 2 | State: [ 0.0558131   0.56643903  0.0229428  -0.8534064 ], Reward: 1.0, Done: False\n",
            "Episode: 2, Step: 3 | State: [ 0.06714188  0.76124084  0.00587467 -1.1387876 ], Reward: 1.0, Done: False\n",
            "Episode: 2, Step: 4 | State: [ 0.0823667   0.9562855  -0.01690109 -1.4296224 ], Reward: 1.0, Done: False\n",
            "Episode: 2, Step: 5 | State: [ 0.1014924   0.76137626 -0.04549354 -1.142269  ], Reward: 1.0, Done: False\n",
            "Episode: 2, Step: 6 | State: [ 0.11671993  0.95706224 -0.06833892 -1.4488648 ], Reward: 1.0, Done: False\n",
            "Episode: 2, Step: 7 | State: [ 0.13586117  0.7628437  -0.09731621 -1.1782931 ], Reward: 1.0, Done: False\n",
            "Episode: 2, Step: 8 | State: [ 0.15111805  0.5691109  -0.12088207 -0.91763455], Reward: 1.0, Done: False\n",
            "Episode: 2, Step: 9 | State: [ 0.16250026  0.3758123  -0.13923477 -0.66525537], Reward: 1.0, Done: False\n",
            "Episode: 2, Step: 10 | State: [ 0.17001651  0.18287347 -0.15253986 -0.4194508 ], Reward: 1.0, Done: False\n",
            "Episode: 2, Step: 11 | State: [ 0.17367399  0.37979054 -0.16092889 -0.7560696 ], Reward: 1.0, Done: False\n",
            "Episode: 2, Step: 12 | State: [ 0.1812698   0.5767215  -0.17605028 -1.0947583 ], Reward: 1.0, Done: False\n",
            "Episode: 2, Step: 13 | State: [ 0.19280422  0.3842996  -0.19794545 -0.86207867], Reward: 1.0, Done: False\n",
            "Episode: 2, Step: 14 | State: [ 0.20049022  0.1923435  -0.21518701 -0.63758373], Reward: 1.0, Done: True\n",
            "Episode 2 finished after 14 steps.\n",
            "Episode: 3, Step: 0 | State: [ 0.01070103  0.2326256   0.02933269 -0.28460845], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 1 | State: [ 0.01535355  0.42731717  0.02364052 -0.5678976 ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 2 | State: [ 0.02389989  0.6220997   0.01228256 -0.8530401 ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 3 | State: [ 0.03634188  0.81705207 -0.00477824 -1.1418357 ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 4 | State: [ 0.05268293  0.6219929  -0.02761495 -0.850655  ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 5 | State: [ 0.06512278  0.81748027 -0.04462805 -1.1518921 ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 6 | State: [ 0.08147239  0.6229681  -0.06766589 -0.87353057], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 7 | State: [ 0.09393175  0.42882824 -0.0851365  -0.60286576], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 8 | State: [ 0.10250831  0.23499377 -0.09719381 -0.33816707], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 9 | State: [ 0.10720819  0.04137954 -0.10395716 -0.0776464 ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 10 | State: [ 0.10803578 -0.15211038 -0.10551009  0.18051322], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 11 | State: [ 0.10499357  0.04435074 -0.10189983 -0.14350213], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 12 | State: [ 0.10588059 -0.14917544 -0.10476986  0.11537458], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 13 | State: [ 0.10289708 -0.34265232 -0.10246237  0.37325257], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 14 | State: [ 0.09604403 -0.53618085 -0.09499732  0.6319516 ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 15 | State: [ 0.08532042 -0.72985804 -0.08235829  0.89327025], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 16 | State: [ 0.07072326 -0.53372145 -0.06449289  0.5758766 ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 17 | State: [ 0.06004883 -0.33775753 -0.05297535  0.26359406], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 18 | State: [ 0.05329368 -0.14192103 -0.04770347 -0.04531607], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 19 | State: [ 0.05045526  0.05385136 -0.04860979 -0.3526601 ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 20 | State: [ 0.05153228 -0.14054686 -0.055663   -0.07569283], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 21 | State: [ 0.04872135 -0.3348285  -0.05717685  0.19892177], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 22 | State: [ 0.04202478 -0.529088   -0.05319842  0.47303405], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 23 | State: [ 0.03144302 -0.72341985 -0.04373774  0.74848646], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 24 | State: [ 0.01697462 -0.91791207 -0.02876801  1.0270909 ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 25 | State: [-0.00138362 -0.7224192  -0.00822619  0.7255164 ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 26 | State: [-0.01583201 -0.5271844   0.00628414  0.4302557 ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 27 | State: [-0.02637569 -0.7223948   0.01488926  0.724913  ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 28 | State: [-0.04082359 -0.5274819   0.02938752  0.43695334], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 29 | State: [-0.05137323 -0.72300726  0.03812658  0.7387534 ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 30 | State: [-0.06583337 -0.52843195  0.05290165  0.45830905], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 31 | State: [-0.07640201 -0.3340962   0.06206783  0.18275905], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 32 | State: [-0.08308394 -0.13991474  0.06572301 -0.08971602], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 33 | State: [-0.08588223  0.05420661  0.06392869 -0.36096072], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 34 | State: [-0.0847981  -0.14176303  0.05670948 -0.04882451], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 35 | State: [-0.08763336  0.05250183  0.05573299 -0.32308972], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 36 | State: [-0.08658332  0.2467877   0.04927119 -0.59768903], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 37 | State: [-0.08164757  0.44118685  0.03731741 -0.87445396], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 38 | State: [-0.07282383  0.6357821   0.01982833 -1.1551749 ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 39 | State: [-0.06010819  0.4404073  -0.00327516 -0.8563411 ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 40 | State: [-0.05130005  0.63557374 -0.02040199 -1.1500521 ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 41 | State: [-0.03858857  0.4407239  -0.04340303 -0.86383593], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 42 | State: [-0.02977409  0.24621883 -0.06067975 -0.5851096 ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 43 | State: [-0.02484971  0.4421359  -0.07238194 -0.89627326], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 44 | State: [-0.016007    0.248066   -0.09030741 -0.6271923 ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 45 | State: [-0.01104568  0.05431285 -0.10285125 -0.3642612 ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 46 | State: [-0.00995942  0.25073466 -0.11013648 -0.68752193], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 47 | State: [-0.00494473  0.05729979 -0.12388691 -0.43144232], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 48 | State: [-0.00379873  0.2539382  -0.13251576 -0.76046896], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 49 | State: [ 0.00128003  0.06086663 -0.14772514 -0.51224643], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 50 | State: [ 0.00249737  0.25772676 -0.15797007 -0.84759384], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 51 | State: [ 0.0076519   0.45460993 -0.17492194 -1.1854917 ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 52 | State: [ 0.0167441   0.6515147  -0.19863178 -1.527507  ], Reward: 1.0, Done: False\n",
            "Episode: 3, Step: 53 | State: [ 0.02977439  0.45926562 -0.22918192 -1.302818  ], Reward: 1.0, Done: True\n",
            "Episode 3 finished after 53 steps.\n",
            "Episode: 4, Step: 0 | State: [ 0.01248763  0.17234008  0.04023944 -0.28755203], Reward: 1.0, Done: False\n",
            "Episode: 4, Step: 1 | State: [ 0.01593443  0.36686575  0.0344884  -0.56727713], Reward: 1.0, Done: False\n",
            "Episode: 4, Step: 2 | State: [ 0.02327175  0.17127743  0.02314286 -0.26393154], Reward: 1.0, Done: False\n",
            "Episode: 4, Step: 3 | State: [ 0.0266973  -0.02416707  0.01786422  0.0359601 ], Reward: 1.0, Done: False\n",
            "Episode: 4, Step: 4 | State: [ 0.02621396 -0.21954058  0.01858343  0.33422542], Reward: 1.0, Done: False\n",
            "Episode: 4, Step: 5 | State: [ 0.02182315 -0.02468798  0.02526793  0.04746019], Reward: 1.0, Done: False\n",
            "Episode: 4, Step: 6 | State: [ 0.02132938  0.1700627   0.02621714 -0.2371446 ], Reward: 1.0, Done: False\n",
            "Episode: 4, Step: 7 | State: [ 0.02473064  0.36480048  0.02147425 -0.5214439 ], Reward: 1.0, Done: False\n",
            "Episode: 4, Step: 8 | State: [ 0.03202665  0.5596137   0.01104537 -0.8072834 ], Reward: 1.0, Done: False\n",
            "Episode: 4, Step: 9 | State: [ 0.04321892  0.3643421  -0.0051003  -0.51114666], Reward: 1.0, Done: False\n",
            "Episode: 4, Step: 10 | State: [ 0.05050576  0.16929236 -0.01532323 -0.22007532], Reward: 1.0, Done: False\n",
            "Episode: 4, Step: 11 | State: [ 0.05389161  0.36462995 -0.01972474 -0.5175522 ], Reward: 1.0, Done: False\n",
            "Episode: 4, Step: 12 | State: [ 0.06118421  0.560024   -0.03007578 -0.8163849 ], Reward: 1.0, Done: False\n",
            "Episode: 4, Step: 13 | State: [ 0.07238469  0.75554454 -0.04640348 -1.118374  ], Reward: 1.0, Done: False\n",
            "Episode: 4, Step: 14 | State: [ 0.08749558  0.9512436  -0.06877096 -1.4252443 ], Reward: 1.0, Done: False\n",
            "Episode: 4, Step: 15 | State: [ 0.10652045  1.1471449  -0.09727585 -1.7386044 ], Reward: 1.0, Done: False\n",
            "Episode: 4, Step: 16 | State: [ 0.12946334  1.3432313  -0.13204794 -2.0598977 ], Reward: 1.0, Done: False\n",
            "Episode: 4, Step: 17 | State: [ 0.15632798  1.1496817  -0.17324589 -1.81081   ], Reward: 1.0, Done: False\n",
            "Episode: 4, Step: 18 | State: [ 0.17932162  0.9568627  -0.20946209 -1.576591  ], Reward: 1.0, Done: True\n",
            "Episode 4 finished after 18 steps.\n",
            "Episode: 5, Step: 0 | State: [ 0.04724459  0.15997201 -0.0026369  -0.3047937 ], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 1 | State: [ 0.05044403  0.35513145 -0.00873277 -0.5983071 ], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 2 | State: [ 0.05754666  0.16013277 -0.02069891 -0.3083876 ], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 3 | State: [ 0.06074931 -0.03468823 -0.02686667 -0.02230375], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 4 | State: [ 0.06005555  0.1608085  -0.02731274 -0.32334086], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 5 | State: [ 0.06327172  0.35630852 -0.03377956 -0.62451047], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 6 | State: [ 0.07039789  0.16167404 -0.04626977 -0.3426546 ], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 7 | State: [ 0.07363137 -0.03276014 -0.05312286 -0.06491391], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 8 | State: [ 0.07297616 -0.2270818  -0.05442114  0.2105466 ], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 9 | State: [ 0.06843453 -0.03122566 -0.0502102  -0.09879459], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 10 | State: [ 0.06781001 -0.22559339 -0.0521861   0.17763397], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 11 | State: [ 0.06329815 -0.4199312  -0.04863342  0.45340806], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 12 | State: [ 0.05489952 -0.22415647 -0.03956525  0.14580062], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 13 | State: [ 0.0504164  -0.41869015 -0.03664924  0.4257436 ], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 14 | State: [ 0.04204259 -0.61327434 -0.02813437  0.7066514 ], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 15 | State: [ 0.02977711 -0.80799544 -0.01400134  0.9903471 ], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 16 | State: [ 0.0136172 -1.0029272  0.0058056  1.2785999], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 17 | State: [-0.00644135 -1.1981226   0.03137759  1.573095  ], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 18 | State: [-0.0304038  -1.0033888   0.06283949  1.2903613 ], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 19 | State: [-0.05047157 -1.1992509   0.08864672  1.6020374 ], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 20 | State: [-0.07445659 -1.0052832   0.12068747  1.3382564 ], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 21 | State: [-0.09456225 -1.2017006   0.1474526   1.6661353 ], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 22 | State: [-0.11859627 -1.3981985   0.1807753   2.0008779 ], Reward: 1.0, Done: False\n",
            "Episode: 5, Step: 23 | State: [-0.14656024 -1.5946898   0.22079286  2.343671  ], Reward: 1.0, Done: True\n",
            "Episode 5 finished after 23 steps.\n",
            "Episode: 6, Step: 0 | State: [ 0.04913047 -0.2325988   0.04365546  0.33333746], Reward: 1.0, Done: False\n",
            "Episode: 6, Step: 1 | State: [ 0.0444785  -0.42831403  0.05032221  0.6394612 ], Reward: 1.0, Done: False\n",
            "Episode: 6, Step: 2 | State: [ 0.03591222 -0.23392849  0.06311143  0.3630405 ], Reward: 1.0, Done: False\n",
            "Episode: 6, Step: 3 | State: [ 0.03123365 -0.03975764  0.07037224  0.09090655], Reward: 1.0, Done: False\n",
            "Episode: 6, Step: 4 | State: [ 0.03043849  0.15428877  0.07219037 -0.17877027], Reward: 1.0, Done: False\n",
            "Episode: 6, Step: 5 | State: [ 0.03352427 -0.04178802  0.06861497  0.13578439], Reward: 1.0, Done: False\n",
            "Episode: 6, Step: 6 | State: [ 0.03268851 -0.23782226  0.07133065  0.44930083], Reward: 1.0, Done: False\n",
            "Episode: 6, Step: 7 | State: [ 0.02793206 -0.43387684  0.08031667  0.76358825], Reward: 1.0, Done: False\n",
            "Episode: 6, Step: 8 | State: [ 0.01925453 -0.6300077   0.09558844  1.0804238 ], Reward: 1.0, Done: False\n",
            "Episode: 6, Step: 9 | State: [ 0.00665437 -0.8262527   0.11719692  1.4015077 ], Reward: 1.0, Done: False\n",
            "Episode: 6, Step: 10 | State: [-0.00987068 -1.0226195   0.14522707  1.7284147 ], Reward: 1.0, Done: False\n",
            "Episode: 6, Step: 11 | State: [-0.03032307 -1.2190722   0.17979535  2.0625384 ], Reward: 1.0, Done: False\n",
            "Episode: 6, Step: 12 | State: [-0.05470452 -1.4155157   0.22104613  2.405029  ], Reward: 1.0, Done: True\n",
            "Episode 6 finished after 12 steps.\n",
            "Episode: 7, Step: 0 | State: [ 0.03315658 -0.20013489  0.01724003  0.26846465], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 1 | State: [ 0.02915388 -0.00526317  0.02260932 -0.0187312 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 2 | State: [ 0.02904861 -0.20070194  0.0222347   0.28099862], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 3 | State: [ 0.02503457 -0.0059041   0.02785467 -0.00458947], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 4 | State: [ 0.02491649  0.18880753  0.02776288 -0.2883554 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 5 | State: [ 0.02869264  0.3835228   0.02199577 -0.5721545 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 6 | State: [ 0.0363631   0.18809944  0.01055268 -0.27262414], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 7 | State: [ 0.04012509  0.38306925  0.0051002  -0.5619601 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 8 | State: [ 0.04778647  0.18787609 -0.00613901 -0.26767474], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 9 | State: [ 0.051544   -0.00715771 -0.0114925   0.02306558], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 10 | State: [ 0.05140084 -0.20211299 -0.01103119  0.31210044], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 11 | State: [ 0.04735858 -0.39707604 -0.00478918  0.60128415], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 12 | State: [ 0.03941706 -0.59213066  0.0072365   0.89245474], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 13 | State: [ 0.02757445 -0.78735006  0.0250856   1.1874036 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 14 | State: [ 0.01182745 -0.5925622   0.04883367  0.90268815], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 15 | State: [-2.3796929e-05 -3.9813456e-01  6.6887431e-02  6.2574577e-01], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 16 | State: [-0.00798649 -0.20400693  0.07940235  0.35485572], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 17 | State: [-0.01206663 -0.01009846  0.08649946  0.08822921], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 18 | State: [-0.0122686  -0.20634693  0.08826405  0.40690047], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 19 | State: [-0.01639553 -0.01258018  0.09640206  0.14329772], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 20 | State: [-0.01664714  0.18103845  0.09926801 -0.11748341], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 21 | State: [-0.01302637 -0.01535534  0.09691834  0.20479387], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 22 | State: [-0.01333348 -0.21172005  0.10101422  0.5264081 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 23 | State: [-0.01756788 -0.01815373  0.11154238  0.26718637], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 24 | State: [-0.01793095  0.17521422  0.11688611  0.01166244], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 25 | State: [-0.01442667  0.36848277  0.11711936 -0.24197593], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 26 | State: [-0.00705701  0.17189956  0.11227984  0.08523323], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 27 | State: [-0.00361902  0.36524794  0.1139845  -0.17002217], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 28 | State: [ 0.00368594  0.55856955  0.11058406 -0.42468387], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 29 | State: [ 0.01485733  0.7519655   0.10209038 -0.6805604 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 30 | State: [ 0.02989664  0.5555849   0.08847918 -0.35756075], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 31 | State: [ 0.04100834  0.7493448   0.08132796 -0.62108487], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 32 | State: [ 0.05599523  0.9432425   0.06890626 -0.8870859 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 33 | State: [ 0.07486008  0.7472563   0.05116454 -0.57356185], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 34 | State: [ 0.08980521  0.941625    0.0396933  -0.84969753], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 35 | State: [ 0.10863771  0.74598485  0.02269935 -0.5448017 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 36 | State: [ 0.1235574   0.5505514   0.01180332 -0.24505405], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 37 | State: [0.13456844 0.35526288 0.00690224 0.05132843], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 38 | State: [ 0.1416737   0.5502852   0.00792881 -0.23916881], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 39 | State: [0.1526794  0.35505086 0.00314543 0.0560045 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 40 | State: [0.15978041 0.15988396 0.00426552 0.3496782 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 41 | State: [0.1629781  0.354945   0.01125908 0.05834335], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 42 | State: [0.170077   0.15966342 0.01242595 0.35455722], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 43 | State: [0.17327026 0.3546065  0.0195171  0.06581832], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 44 | State: [0.18036239 0.15921026 0.02083346 0.36459455], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 45 | State: [ 0.1835466  -0.03620148  0.02812535  0.6637731 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 46 | State: [0.18282257 0.15851815 0.04140082 0.38007697], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 47 | State: [0.18599293 0.35302848 0.04900236 0.10072985], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 48 | State: [ 0.1930535   0.54741514  0.05101695 -0.17609923], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 49 | State: [ 0.2040018   0.7417713   0.04749497 -0.45226163], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 50 | State: [ 0.21883723  0.546011    0.03844974 -0.144994  ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 51 | State: [0.22975744 0.35036007 0.03554986 0.15956686], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 52 | State: [0.23676465 0.15474766 0.03874119 0.4632495 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 53 | State: [0.2398596  0.34930134 0.04800618 0.18302508], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 54 | State: [ 0.24684563  0.5437047   0.05166668 -0.09413559], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 55 | State: [ 0.25771973  0.7380495   0.04978397 -0.37008056], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 56 | State: [ 0.27248073  0.9324301   0.04238236 -0.64665973], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 57 | State: [ 0.29112932  0.736744    0.02944917 -0.34093755], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 58 | State: [ 0.30586419  0.5412157   0.02263042 -0.03911546], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 59 | State: [0.3166885  0.34577665 0.02184811 0.2606208 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 60 | State: [ 0.32360405  0.54058003  0.02706052 -0.02509167], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 61 | State: [ 0.33441564  0.73530364  0.02655869 -0.30911538], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 62 | State: [ 0.34912172  0.5398136   0.02037638 -0.00817629], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 63 | State: [0.359918   0.3444054  0.02021286 0.29086533], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 64 | State: [0.3668061  0.5392334  0.02603016 0.00462523], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 65 | State: [0.37759078 0.343748   0.02612267 0.305406  ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 66 | State: [0.38446572 0.53848815 0.03223079 0.02107464], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 67 | State: [0.39523548 0.34291914 0.03265228 0.32375   ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 68 | State: [0.40209386 0.5375613  0.03912728 0.04154044], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 69 | State: [ 0.4128451   0.73210096  0.03995809 -0.23854524], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 70 | State: [0.4274871  0.5364316  0.03518718 0.06646904], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 71 | State: [0.43821573 0.34082332 0.03651657 0.37004277], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 72 | State: [0.4450322  0.1452021  0.04391742 0.6740125 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 73 | State: [ 0.44793627 -0.05050183  0.05739767  0.9801929 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 74 | State: [0.4469262  0.14380574 0.07700153 0.70607716], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 75 | State: [0.44980234 0.33778116 0.09112307 0.43859228], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 76 | State: [0.45655796 0.5315032  0.09989492 0.17596792], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 77 | State: [ 0.46718803  0.72506416  0.10341427 -0.0836058 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 78 | State: [ 0.4816893   0.9185634   0.10174216 -0.34195435], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 79 | State: [ 0.50006056  0.72215223  0.09490307 -0.01900048], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 80 | State: [ 0.5145036   0.9157941   0.09452306 -0.28029656], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 81 | State: [ 0.5328195   1.1094495   0.08891713 -0.5417346 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 82 | State: [ 0.5550085   1.3032166   0.07808244 -0.80512977], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 83 | State: [ 0.5810728   1.107116    0.06197985 -0.48894224], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 84 | State: [ 0.60321516  0.91117686  0.052201   -0.1773875 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 85 | State: [0.6214387  0.71534824 0.04865325 0.13129543], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 86 | State: [ 0.63574564  0.90974075  0.05127916 -0.14564982], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 87 | State: [0.65394044 0.71392334 0.04836616 0.16275962], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 88 | State: [ 0.6682189   0.9083207   0.05162135 -0.11428137], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 89 | State: [0.68638533 0.7124986  0.04933573 0.19423053], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 90 | State: [ 0.7006353   0.9068814   0.05322034 -0.08249004], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 91 | State: [0.71877295 0.7110385  0.05157053 0.22649771], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 92 | State: [0.7329937  0.5152189  0.05610049 0.5349916 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 93 | State: [0.74329805 0.70950896 0.06680032 0.26049992], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 94 | State: [0.75748825 0.51350015 0.07201032 0.5734821 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 95 | State: [0.76775825 0.31744638 0.08347996 0.88795334], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 96 | State: [0.7741072  0.12129669 0.10123903 1.2056679 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 97 | State: [0.7765331  0.3149752  0.12535238 0.9463511 ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 98 | State: [0.7828326  0.11840834 0.1442794  1.275645  ], Reward: 1.0, Done: False\n",
            "Episode: 7, Step: 99 | State: [0.7852008  0.311426   0.16979231 1.0313979 ], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 0 | State: [ 0.00415241 -0.14758798  0.01446677  0.33520702], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 1 | State: [ 0.00120065 -0.3429128   0.02117091  0.63241667], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 2 | State: [-0.0056576  -0.14809251  0.03381924  0.34647548], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 3 | State: [-0.00861945  0.04653247  0.04074875  0.06464592], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 4 | State: [-0.0076888   0.24104722  0.04204167 -0.21490718], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 5 | State: [-0.00286786  0.04535023  0.03774352  0.09073553], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 6 | State: [-0.00196085  0.23991144  0.03955824 -0.18980445], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 7 | State: [0.00283737 0.04424653 0.03576215 0.11509037], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 8 | State: [ 0.0037223   0.2388383   0.03806395 -0.16609882], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 9 | State: [ 0.00849907  0.4333953   0.03474198 -0.4465348 ], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 10 | State: [ 0.01716698  0.62800896  0.02581128 -0.7280671 ], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 11 | State: [ 0.02972716  0.43253988  0.01124994 -0.42737344], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 12 | State: [ 0.03837795  0.6275007   0.00270247 -0.7164888 ], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 13 | State: [ 0.05092797  0.43234146 -0.01162731 -0.42295644], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 14 | State: [ 0.0595748   0.23738614 -0.02008643 -0.13396159], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 15 | State: [ 0.06432252  0.43278995 -0.02276567 -0.4329132 ], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 16 | State: [ 0.07297832  0.23799762 -0.03142393 -0.14749293], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 17 | State: [ 0.07773827  0.04333943 -0.03437379  0.13511309], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 18 | State: [ 0.07860506  0.23893644 -0.03167153 -0.16821302], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 19 | State: [ 0.08338379  0.04428181 -0.03503579  0.11431262], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 20 | State: [ 0.08426943  0.2398878  -0.03274953 -0.18921472], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 21 | State: [ 0.08906718  0.04524932 -0.03653383  0.09295981], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 22 | State: [ 0.08997217  0.24087535 -0.03467463 -0.21102199], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 23 | State: [ 0.09478968  0.4364755  -0.03889507 -0.5144381 ], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 24 | State: [ 0.10351919  0.24192227 -0.04918383 -0.23426127], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 25 | State: [ 0.10835763  0.43771118 -0.05386906 -0.54204375], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 26 | State: [ 0.11711185  0.24338609 -0.06470994 -0.26680878], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 27 | State: [ 0.12197958  0.43936905 -0.07004611 -0.57917935], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 28 | State: [ 0.13076696  0.6353991  -0.0816297  -0.8930801 ], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 29 | State: [ 0.14347494  0.44147354 -0.0994913  -0.62713283], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 30 | State: [ 0.15230441  0.2478707  -0.11203396 -0.3673669 ], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 31 | State: [ 0.15726182  0.44439152 -0.11938129 -0.6931692 ], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 32 | State: [ 0.16614965  0.6409495  -0.13324468 -1.0209225 ], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 33 | State: [ 0.17896864  0.83757085 -0.15366313 -1.3522984 ], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 34 | State: [ 0.19572006  0.6446757  -0.1807091  -1.1113644 ], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 35 | State: [ 0.20861357  0.45232737 -0.20293638 -0.8803798 ], Reward: 1.0, Done: False\n",
            "Episode: 8, Step: 36 | State: [ 0.21766013  0.26045448 -0.22054398 -0.6577312 ], Reward: 1.0, Done: True\n",
            "Episode 8 finished after 36 steps.\n",
            "Episode: 9, Step: 0 | State: [-0.0055699   0.23660848 -0.00104566 -0.25621772], Reward: 1.0, Done: False\n",
            "Episode: 9, Step: 1 | State: [-0.00083773  0.04150147 -0.00617002  0.03613519], Reward: 1.0, Done: False\n",
            "Episode: 9, Step: 2 | State: [-7.7027280e-06 -1.5353146e-01 -5.4473123e-03  3.2686505e-01], Reward: 1.0, Done: False\n",
            "Episode: 9, Step: 3 | State: [-0.00307833  0.04166762  0.00108999  0.03246927], Reward: 1.0, Done: False\n",
            "Episode: 9, Step: 4 | State: [-0.00224498  0.23677392  0.00173937 -0.25986955], Reward: 1.0, Done: False\n",
            "Episode: 9, Step: 5 | State: [ 0.0024905   0.431871   -0.00345802 -0.5520033 ], Reward: 1.0, Done: False\n",
            "Episode: 9, Step: 6 | State: [ 0.01112792  0.23679778 -0.01449808 -0.26041192], Reward: 1.0, Done: False\n",
            "Episode: 9, Step: 7 | State: [ 0.01586387  0.43212366 -0.01970632 -0.55763227], Reward: 1.0, Done: False\n",
            "Episode: 9, Step: 8 | State: [ 0.02450635  0.23728383 -0.03085897 -0.2712225 ], Reward: 1.0, Done: False\n",
            "Episode: 9, Step: 9 | State: [ 0.02925202  0.4328322  -0.03628342 -0.57347655], Reward: 1.0, Done: False\n",
            "Episode: 9, Step: 10 | State: [ 0.03790867  0.23823726 -0.04775295 -0.29244122], Reward: 1.0, Done: False\n",
            "Episode: 9, Step: 11 | State: [ 0.04267341  0.4340064  -0.05360177 -0.5997942 ], Reward: 1.0, Done: False\n",
            "Episode: 9, Step: 12 | State: [ 0.05135354  0.23967372 -0.06559766 -0.32446522], Reward: 1.0, Done: False\n",
            "Episode: 9, Step: 13 | State: [ 0.05614702  0.04554414 -0.07208696 -0.05316902], Reward: 1.0, Done: False\n",
            "Episode: 9, Step: 14 | State: [ 0.0570579   0.24162172 -0.07315034 -0.36769673], Reward: 1.0, Done: False\n",
            "Episode: 9, Step: 15 | State: [ 0.06189033  0.43770275 -0.08050428 -0.6825187 ], Reward: 1.0, Done: False\n",
            "Episode: 9, Step: 16 | State: [ 0.07064439  0.6338449  -0.09415465 -0.9994218 ], Reward: 1.0, Done: False\n",
            "Episode: 9, Step: 17 | State: [ 0.08332129  0.83009064 -0.11414309 -1.3201271 ], Reward: 1.0, Done: False\n",
            "Episode: 9, Step: 18 | State: [ 0.0999231   1.0264554  -0.14054564 -1.6462429 ], Reward: 1.0, Done: False\n",
            "Episode: 9, Step: 19 | State: [ 0.12045221  0.83322966 -0.17347048 -1.4004467 ], Reward: 1.0, Done: False\n",
            "Episode: 9, Step: 20 | State: [ 0.1371168   1.0300306  -0.20147942 -1.7419624 ], Reward: 1.0, Done: False\n",
            "Episode: 9, Step: 21 | State: [ 0.1577174   1.2267954  -0.23631868 -2.0899744 ], Reward: 1.0, Done: True\n",
            "Episode 9 finished after 21 steps.\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "from time import sleep\n",
        "\n",
        "env = gym.make('CartPole-v1', render_mode=\"human\")\n",
        "\n",
        "def random_games(episodes: int=10, steps: int=100) -> None:\n",
        "    for episode in range(episodes):\n",
        "        env.reset()\n",
        "\n",
        "        for step in range(steps):\n",
        "            # env.render()  # render the environment when X11 is available\n",
        "\n",
        "            action = env.action_space.sample()\n",
        "            state_next, reward, terminated, info = env.step(action)\n",
        "            print(f\"Episode: {episode}, Step: {step} | State: {state_next}, Reward: {reward}, Done: {terminated}\")\n",
        "\n",
        "            if terminated:\n",
        "                print(f\"Episode {episode} finished after {step} steps.\")\n",
        "                break\n",
        "\n",
        "            sleep(0.1)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    random_games()\n",
        "    env.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lGFAtdIoTtQD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}